+++
author = "Eldridge Alexander"
date = 2022-08-12T02:03:11Z
description = "Requiring proof of identity online hurts the marginalized"
draft = false
image = "img/photo-id-required.jpg"
slug = "online-identity-is-complicated"
title = "Online Identity is Complicated"

+++

I am seeing increasing calls for identity verification to be a fundamental part of online presence, especially in places like Twitter where disinformation thrives. The premise is ensuring comments are connected to an identity will help prevent hate speech, disinformation, and scams. This is a bad idea. Or at the very least, lacks nuance. It falls into the trap tech always seems to fall into – pushing for major change without ensuring we have marginalized people at the table and in the discussion before we make these changes.

Me and people like me are already at this table. Others are not, and this would affect them differently, and place many of them into real physical danger. Enforcing identity is great at reducing problems. As long as you’re straight, white, male, and American. For others it’s not quite as clear cut. 

To be clear, I’m not trying to land on one side of the identity debate or another. I’m trying to inject nuance into the conversation and make sure we don’t leave certain groups out of the conversation as a whole, as we have done so many times before. A perennial problem in almost all of tech is we don’t stop to consider externalities. This is especially true for people that aren’t in the same demographics as the biggest creators and consumers of that technology. That’s happening here. 

I’m sure I can’t speak to all those affected but I want to talk about how these policies have affected members of the LGBT+ community in the past, and how it will inevitably do so in the future. It’s pretty straightforward. Members of marginalized communities, such as LGBT+, often find support in online groups, but don’t want that associated with their in real life (irl) identities. Exposing that identity can cause grief, and sometimes puts them at risk of violence or death.

We already have a case study here in Google+. Google+ [had a "real name" policy] (https://slate.com/technology/2014/07/google-plus-finally-ditches-its-ineffective-dangerous-real-name-policy.html) that is similar to current proposals. But they ditched it due in part to the danger it caused. They [outed a trans woman](https://www.theguardian.com/technology/2014/jan/07/google-hangouts-faces-criticism-after-outing-trans-woman) when Google decided to apply these policies to Hangouts. While you could argue that this wouldn’t have happened if the policies had been rolled out more thoughtfully, rolling out massive changes with great thoughtfulness has never been the tech industry's forte. 

Insisting on identity in forums were marginalized people can currently gather in relative safety seems myopic, Especially when we’re seeing [increases](https://www.hrc.org/press-releases/new-fbi-hate-crimes-report-shows-increases-in-anti-lgbtq-attacks) in [instances](https://www.huffpost.com/entry/lgbtq-violence-trump_n_5a625035e4b002283002897b) of [violence](https://ucr.fbi.gov/hate-crime/2018/hate-crime) against LGBT+ people. And we are seeing a similar rise in hate crimes against Asian-Americans, with [instances increasing 339% last year alone](https://www.nbcnews.com/news/asian-america/anti-asian-hate-crimes-increased-339-percent-nationwide-last-year-repo-rcna14282). Rise in violence against the marginalized combined with the [ongoing rise in swatting attacks](https://arstechnica.com/gaming/2015/02/gamer-gets-swatted-while-streaming-before-60000-viewers/) makes this exceptionally dangerous.[^1]

[^1]: [Swatting](https://en.wikipedia.org/wiki/Swatting) is calling law enforcement and reporting a false crime with the intent to have police send a SWAT team, often resulting in injury or death.

Not only that, but it glosses over the fact that there are support and gathering groups online that will become hunting grounds for certain types of people and prosecutors. We are seeing the rise of legal cannabis all over the country, for recreational use, but also for medicinal use. In many situations providing a viable alternative to highly addictive opiates.

Having a safe place to discuss this without fear of decades in prison was important. 
As the Supreme Court removes what were previously constitutional rights, this is even more crucial. What innocuous conversations are you having online today that might make you liable for a $10,000 civil lawsuit a year from now. 

And this is not even getting into those living under regimes which make this situation much worse. In the US many of the problems I listed are fellow citizens using someone’s identity to commit a crime (usually violence) against them. This is terrible, but in some countries that violence is not only legal, but actually perpetrated against the person by their own government. 

I don’t have a grand solution unfortunately. It seems that lack of identity contributes to death threats, scams, and disinformation. But enforcing identity causes great risk and harm to the most vulnerable among us. Any answer that comes up in this space will not be a straightforward or simple one.[^2]

[^2]: If someone suggests a "simple" solution here and uses the word "blockchain", just run away.

One method that might help is, via corporate policy or government regulation, prohibiting amplifying *any* account in feeds (e.g. Twitter, TikTok) unless identity is verified. Anyone can follow anyone but you won’t ever see a "suggestion" from a non-verified account, preventing their amplification effect. 
"
Another might be stronger "liveness" testing. Some [proposals](https://www.theverge.com/2021/5/16/22436395/cloudflare-end-captcha-madness-security-key-cryptographic-attestation-of-personhood) already exist to make this better than the current captcha system. This could also utilize the biometrics that modern devices provide.[^3] This could be rolled out in tandem with making bot registration much more thorough. Twitter is already [experimenting](https://blog.twitter.com/common-thread/en/topics/stories/2021/the-secret-world-of-good-bots) in this area. Making liveness testing much more frequent, but *much* easier than captchas, and forcing bots through a separate system that requires strong identity attestation to an individual or company would allow good bots to continue while limiting malicious bots.
[^3]: Beyond the scope of this post but OS integrated biometrics stored in a secure enclave on your device (e.g. fingerprint scanner or FaceID) is much safer and radically different from centrally stored biometrics (e.g. using your face as a Delta boarding pass).

Hate speech, disinformation, death threats – these are all terrible things that happen online that *might* be improved or reduced by enforcing identity. But we know from experience that enforcing identity will cause crimes, violence, death, and legal trouble.

Tech has a long history of ignoring the marginalized. These efforts around identity come for a good place – a desire to see social and online media improve and to counteract some of its most pernicious problems. But even in an attempt to do good with social media, to help the general public, we again risk leaving out the vulnerable and causing more harm than good. And, as we’ve seen, once information is public it’s close to impossible to claw back. We must tread carefully here.
